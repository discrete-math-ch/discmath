import { Callout, Tabs} from 'nextra/components'
import Problem from '@/components/problem'
import Image from 'next/image'

import { Cards } from 'nextra/components'
 


# Relations

Relations are super useful and a basic conecpt in many areas of mathematics and computer science. We can build this concept basically directly from what we learned from set theory. You already know many examples, like $\leq$ and $>$, and so on. We will also see that functions are simply relations with a special property.



<Callout type="axiom">
**Definition 3.9**: A *(binary)* relation $\rho$ from a set $A$ to a set $B$ (also called an $(A, B)$-
relation) is a subset of $A \times B$. If $A = B$, then $\rho$ is called a relation on $A$.
</Callout>

Often times we will see something like:

> Given some relation $\rho$ on $A$ that is ..., prove that $\rho$ fulfills ...

<Cards>
  <Cards.Card
    title="Intuition"
    href="/content/ch3/relations#intuition"
  />
  <Cards.Card
    title="Theory"
    href="/content/ch3/relations#theory"
  />
  <Cards.Card
    title="Exercises"
    href="/content/ch3/relations#exercises"
  />
</Cards>
## Intuition

<Callout type="warning">
Don't use intuition to argue or prove something. This is only meant to be to get an idea of a proof, on logic level or to get an idea whether some statment is true or false. For example about statements like *there is a relation that is ... and ...*. Additionally this intuition will probably make it easier to find counterexamples. But still, you have to always argue using definitions and logic.
</Callout>

### Graphs
<Callout type="warning">
This is not to be confsed with [Hasse Diagrams](#hasse-Diagrams) for partial order relations
</Callout>

Really, if you think about a relation $\rho \subseteq A \times A$ (i.e. a relation which is defined *on* one set $A$, which might be generic) and you have some [property](#properties), think about the directed graph representation of this property - draw it! Oftetimes, this feels like cheating, because some exercises seem trivial when looking at them in graph representation. After learning about graphs in A&D, you might even be tempted to think about what the different graph algorithms and properties mean in the context of relations.

So what is the graph representation?

1. We use *nodes* to depict elements of the set $A$. Of course, oftentimes $A$ is an arbitrary/generic set, we can still draw some dots for the elements of $A$ to try to understand the structure of the relation.

2. For each element $(a,b) \in \rho$ draw an arrow from node $a$ to node $b$. If we again have some generic relation, which satisfies certain properties, try to understand how these properties are represented in your graph. I will elaborate it in the section on [properties](#properties). However it is a good practice to do so.

<details>
<summary>Example: $\ A = \{1,2,3,4,5,6,7,8\}$</summary>
Consider the set $A = \{1,2,3,4,5,6,7,8\}$ and the relation
$$
\rho = \{(1,2),(1,3),(1,4),(2,4),(3,7),(3,8),(2,5),(4,5),(5,6),(6,7),(7,8)\}
$$
Then we obtain the following graph reprensentation


<figure
  className="block my-10 text-center break-inside-avoid-column">
  <center>
  <Image
    width="500"
    height="500"
    className="object-cover rounded-xl align-center"
    src="/relations/plain.png">
  </Image>
  </center>
  <figcaption className="z-10 mt-4 text-sm italic text-gray-600">
  Simple graph reprensentation - by Tobias Steinbrecher
  </figcaption>
</figure>

</details>

### Matrices

<Callout type="warning">
The formalities defined in this section on matrices are not
covered in the lecture. However, it might help deepening the understanding
of the topic.
</Callout>

For relations on finite sets $A, B$ we can also represent relations as matrices
in $\{0, 1\}^{n \times m}$ where $n = |A|$ and $m = |B|$.
The matrix representation gives us an additional tool to understand
different properties and operations on relations.

Let $A = \{a_1, \dots, a_n\}$ and $B = \{b_1, \dots, b_m\}$,
$\rho \subseteq A \times B$. We define $M^{\rho} \in \{0, 1\}^{n \times m}$ as follows:
$$
M^{\rho}(i,j) = a_i \rho b_j \\
$$

Thus
$$
M^{\rho} = \begin{pmatrix}
 a_1 \rho b_1 & a_1 \rho b_2 & \dots & a_1 \rho b_m \\
  a_2 \rho b_1 & a_2 \rho b_2 & \dots & a_2 \rho b_m \\
  \vdots & \vdots & \ddots & \vdots \\
  a_n \rho b_1 & a_n \rho b_2 & \dots & a_n \rho b_m \\
\end{pmatrix}
$$

<details>
<summary>Example:  $\ \rho = \{ (1, 3), (2, 1), (3, 2), (4, 1) \}$</summary>

Let $A = B = \{1,2,3,4\}$ and $\rho = \{ (1, 3), (2, 1), (3, 2), (4, 1) \}$.
 Then:
$$
M^{\rho} = \begin{pmatrix}
 0 & 0 & 1 & 0 \\
 1 & 0 & 0 & 0 \\
 0 & 1 & 0 & 0 \\
 1 & 0 & 0 & 0 \\
\end{pmatrix}
$$

</details>

#### Matrix Operations

In Linear Algebra we have seen component-wise addition on matrices.
Here we will define similar component-wise operations $+$ (OR) and $\ast$ (AND).
Note that these definitions are the same as in LinAlg but since these matrices
contain truth values instead of numbers, we define scalar addition as OR and scalar multiplication as AND.

<Callout type="info">
In Algebra (chapter 5) you will see that these operations correspond to
addition and multiplication on the field $\mathbb{Z}_2$ and the
matrices are elements of the vector space $\mathbb{Z}_2^{n \times m}$.
</Callout>

<br/>

$$
\begin{aligned}

(A + B)_{i,j} &= A_{i,j} \lor B_{i,j} \\
(A \ast B)_{i,j} &= A_{i,j} \land B_{i,j} \\

\end{aligned}

$$
Thus

$$
\begin{aligned}
A + B &= \begin{pmatrix}
A_{1,1} \lor B_{1,1} & \dots & A_{1,m} \lor B_{1,m} \\
\vdots & \ddots & \vdots \\
A_{1,n} \lor B_{1,n} & \dots & A_{n,m} \lor B_{n,m} \\
\end{pmatrix} \\


A \ast B &= \begin{pmatrix}
A_{1,1} \land B_{1,1} & \dots & A_{1,m} \land B_{1,m} \\
\vdots & \ddots & \vdots \\
A_{1,n} \land B_{1,n} & \dots & A_{n,m} \land B_{n,m} \\
\end{pmatrix} \\
\end{aligned}
$$

We define standard matrix multiplication again using OR as addition and AND as scalar multiplication:

$$
(A \cdot B)_{i,j} = \bigvee_{k=1}^{n} A_{i,k} \land B_{k,j}
$$



#### Operations on Relations

Proven by intimidation or alternatively by the reader, we can find
the following correspondance between operations on relations and operations on matrices:

$$
M^{\rho \cap \sigma} = M^{\rho} \ast M^{\sigma} \\
M^{\rho \cup \sigma} = M^{\rho} + M^{\sigma} \\
M^{\rho \circ \sigma} = M^{\rho} \cdot M^{\sigma} \\
M^{\hat\rho} = (M^{\rho})^\top \\
$$

$$
\rho \subseteq \sigma \iff M^{\rho} \ast M^{\sigma} = M^{\rho} \\
$$

For a relation $\rho$ on $A$ we further find that
$$
M^{\rho^k} = (M^{\rho})^k \\
M^{\rho^*} = \sum_{k \in \mathbb{N}\setminus\{0\}} (M^{\rho})^k
$$

The transitive closure of a relation $\rho$ can be determined algorithmically
using the following pseudocode. It can be shown that the while loop
terminates after at most $\mathcal{O}(\log n)$ iterations.


```python
A = zero_matrix(n,n)
B = matrix(\rho)
while A != B:
    A = B
    B += B.multiply(B)
return A
```

#### Special Relation Matrices

$$
\begin{aligned}
\rho \text{ is reflexive}
  &\iff \text{for all } 1 \leq i \leq n  \hspace{1em} M^{\rho}_{i,i} = 1 \\
  &\iff \text{diagonal of } M^\rho \text{ all } 1 \\[2em]


\rho \text{ is irreflexive}
  &\iff \text{for all } 1 \leq i \leq n  \hspace{1em} M^{\rho}_{i,i} = \textbf{0}_n \\
  &\iff \text{diagonal of } M^\rho \text{ all 0} \\[2em]


\rho \text{ is symmetric} &\iff M^{\rho} = (M^{\rho})^\top \\
  &\iff \text{for all } 1 \leq i,j \leq n  \hspace{1em} M^{\rho}_{i,j} = M^{\rho}_{j,i} \\
  &\iff \text{matrix } M^\rho \text{ is symmetric} \\[2em]


\rho \text{ is antisymmetric}
  &\iff \text{for all } 1 \leq i,j \leq n  \hspace{1em} M^{\rho}_{i,j} \land M^{\rho}_{j,i} = \textbf{0}_n \\[2em]


\rho \text{ is transitive} &\iff (M^{\rho})^2 \ast M^{\rho} = (M^{\rho})^2 \\
\end{aligned}
$$

## Theory

### Properties


#### Reflexive Relations

<Callout type="-">
A relation is called $\rho$ is called *reflexive*, if for all $a \in A$:
$$
a \rho a
$$
</Callout>

To prove **reflexivity** of a relation, we often start with something like:

> Let $a \in A$ be arbitrary...

Then our goal is to derive that $a \rho a$ (from some given proeprties about $\rho$).

In the graph visualization of a reflexive relation, we must have a self-loop at each node:

<figure
  className="block my-10 text-center break-inside-avoid-column">
  <center>
  <Image
    width="500"
    height="500"
    className="object-cover rounded-xl align-center"
    src="/relations/ref.png">
  </Image>
  </center>
  <figcaption className="z-10 mt-4 text-sm italic text-gray-600">
  Example of a graph of a reflexive relation - by Tobias Steinbrecher
  </figcaption>
</figure>


#### Irreflexive Relations

<Callout type="-">
A relation $\rho$ is called *irreflexive* if for all $a \in A$:
$$
\lnot(a \rho a)
$$
</Callout>

#### Symmetric Relation

<Callout type="-">
A relation is called *symmetric* if for all $a,b\in A$:

$$
a \rho b \implies b \rho c
$$
</Callout>

To prove **symmetry** of a relation, we often start with something like:

> Let $a,b \in A$ be arbitrary, such that $a \rho b$.
> $$
> \begin{aligned}
> a \rho b &\overset{\cdot}{\implies} \dots \\
> & \overset{\cdot}{\implies} \dots \\
> &\overset{\cdot}{\implies} b \rho a
> \end{aligned}
> $$
> Therefore $\dots$

In the graph representation, all the edges have to go in both directions:
<figure
  className="block my-10 text-center break-inside-avoid-column">
  <center>
  <Image
    width="500"
    height="500"
    className="object-cover rounded-xl align-center"
    src="/relations/symm.png">
  </Image>
  </center>
  <figcaption className="z-10 mt-4 text-sm italic text-gray-600">
  Example of a graph of a symmetric relation - by Tobias Steinbrecher
  </figcaption>
</figure>


#### Transitive Relations
<Callout type="-">
A relation is called *transitive* if for all $a,b,c \in A$:

$$
a \rho b \land b \rho c \implies a \rho c
$$
</Callout>

To prove **transitiviy** of a relation, we often start with something like:

> Let $a,b,c \in A$ be arbitrary, such that $a \rho b$ and $b \rho c$.
> $$
> \begin{aligned}
> a \rho b \land b \rho c &\overset{\cdot}{\implies} \dots \\
> & \overset{\cdot}{\implies} \dots \\
> &\overset{\cdot}{\implies} a \rho c
> \end{aligned}
> $$
> Therefore $\dots$

The following graph is an example of a transitive relation

<figure
  className="block my-10 text-center break-inside-avoid-column">
  <center>
  <Image
    width="500"
    height="500"
    className="object-cover rounded-xl align-center"
    src="/relations/transitive.png">
  </Image>
  </center>
  <figcaption className="z-10 mt-4 text-sm italic text-gray-600">
  Example of a graph of a transitive relation - by Tobias Steinbrecher
  </figcaption>
</figure>


#### Antisymmetric Relation

<Callout type="-">
A relation is called *antisymmetric* if for all $a,b \in A$:
$$
a \rho b \land b\rho a \implies a = b
$$
</Callout>

To prove **antisymmetry** of a relation, we often start with something like:

> Let $a,b \in A$ be arbitrary, such that $a \rho b$ and $b \rho a$.
> $$
> \begin{aligned}
> a \rho b \land b \rho a &\overset{\cdot}{\implies} \dots \\
> & \overset{\cdot}{\implies} \dots \\
> &\overset{\cdot}{\implies} a = b
> \end{aligned}
> $$
> Therefore $\dots$

In the graph of a transitive relation, it can never be the case that there is an edge from node $a$ to $b$ and an edge from node $b$ to $a$. Otherwise, the two elements corresponding to the nodes would have to be equal, which is a contradiction, as we draw different nodes for different elements.


### Equivalence Relations


#### Equivalence classes



### Partial Order Relations


#### Hasse Diagrams


#### Special Elements in Posets

#### Lattices

## Exercises

### Verifying Properties

<Problem title="Commutativity of Matrices" difficulty="🐹" source="Tobias Steinbrecher">
  <div label="question">
    Let $\mathbb{R}^{n \times n}$ be the set of all $n \times n$ matrices over the reals. Define a relation $\sim$ on $\mathbb{R}^{n \times n}$ by
    $$
    A \sim B \iff AB = BA
    $$
     Prove or disprove the following properties:

    1. $\sim$ is reflexive
    2. $\sim$ is symmetric
    3. $\sim$ is transitive

  </div>
  <div label="answer">
    Let's analyze each property of the relation $\sim$ (commutativity of matrices):

    1. **Reflexivity**:
    We need to prove that for every matrix $A \in \mathbb{R}^{n \times n}$, we have $A \sim A$, i.e., $AA = AA$. This is clearly true because matrix multiplication is always commutative with itself. Therefore, the relation $\sim$ is **reflexive**.

    2. **Symmetry**:
    We need to prove that if $A \sim B$ (i.e., $AB = BA$), then $B \sim A$ (i.e., $BA = AB$). With the symmetry of the $=$ relation, we obtain that $AB = BA$ implies $BA = AB$, therefore $B \sim A$ and the relation is **symmetric**.

    3. **Transitivity**:
    Consider two arbitrary $n\times n$ matrices $A$ and $B$ which do not commute. Such matrices exists, because matrix multiplication is not commutative in general. However, every matrix does commute with the identity, as $A I = A =IA$ for arbitrary $A \in \mathbb{R}^{n \times n}$.
    Therefore, we have $A \sim I$ and $I \sim B$, but not $A \sim B$, which contradicts transitivity

    Therefore, the relation $\sim$ is reflexive, symmetric, but not transitive.
  </div>
</Problem>


### Ad-hoc

<Problem title="Collatz Conjecture" source="Max Obreiter">
    <div label="question">
        The [Collatz Conjecture](https://en.wikipedia.org/wiki/Collatz_conjecture) states that for any positive integer $x_0 = n$, the following sequence will eventually reach 1:
        $$
        x_{n + 1} = \begin{cases}
            x_n / 2 & \text{if } x_n \text{ is even} \\
            3x_n + 1 & \text{if } x_n \text{ is odd}
        \end{cases}
        $$
        Give a formula in predicate logic that is true iff the Collatz Conjecture is true. (Note that predicates are not allowed to be recursive.) The universe should be $U = \mathbb N \setminus \{ 0 \}$.
    </div>
    <div label="hint">
        Define some relation.
    </div>
    <div label="hint">
        Let's define the relation $\rho$ as:
        $$
            a \rho b \iff b = \begin{cases}
                a / 2 & \text{if } a \text{ is even} \\
                3a + 1 & \text{if } a \text{ is odd}
            \end{cases}
        $$
    </div>
    <div label="answer">
        There are two easy answers to this question.

        The first one is straightforward given the relation $\rho$ (see hint):
        $$
            \forall n \left[ \exists m(a \rho^m 1) \right]
        $$
        Intuitively, this means that for every positive natural number $n$, there exists a finite number of steps ($m$), such that $n$ reaches $1$.
    </div>
    <div label="answer">
        Another way to capture the "$n$ eventually reaches $1$" idea is to use the transitive closure of the relation $\rho$:
        $$
            \rho^* = \bigcup_{i=0}^\infty \rho^i
        $$
        Intuitively, $a \rho^* b$ if there is a finite amount of "steps" from $a$ to $b$.

        Then the formula would be:
        $$
            \forall n \left[ n \rho^* 1 \right]
        $$
    </div>
</Problem>

### Equivalence Relations

<Problem title="Intersection of equivalence relations" source="Lemma 3.10">
    <div label="question">
        Let $\rho$ and $\sigma$ be equivalence relations on a set $A$. Prove that $\rho \cap \sigma$ is also an equivalence relation on $A$.
    </div>
    <div label="hint">
        Recall the definition of an equivalence relation. You need to show that $\rho \cap \sigma$ is reflexive, symmetric, and transitive.
    </div>
    <div label="answer">
        To show that $\rho \cap \sigma$ is an equivalence relation, we need to prove that it is reflexive, symmetric, and transitive:

        **Reflexive**: Let $a \in A$ be arbitrary but fixed:
        $$
            \begin{aligned}
                &(a, a) \in \rho \land (a, a) \in \sigma && \rho, \sigma \text{ are reflexive} \\
                \dot\implies & (a, a) \in (\rho \cap \sigma) && \text{Def. $\cap$} \\
            \end{aligned}
        $$

        **Symmetric**: Let $a, b \in A$ be arbitrary but fixed:
        $$
            \begin{aligned}
                &(a, b) \in (\rho \cap \sigma) \\
                \dot\implies & (a, b) \in \rho \land (a, b) \in \sigma && \text{Def. $\cap$} \\
                \dot\implies & (b, a) \in \rho \land (b, a) \in \sigma && \rho, \sigma \text{ are symmetric} \\
                \dot\implies & (b, a) \in (\rho \cap \sigma) && \text{Def. $\cap$} \\
            \end{aligned}
        $$

        **Transitive**: Let $a, b, c \in A$ be arbitrary but fixed:
        $$
            \begin{aligned}
                &(a, b) \in (\rho \cap \sigma) \land (b, c) \in (\rho \cap \sigma) \\
                \dot\implies & (a, b) \in \rho \land (a, b) \in \sigma \land (b, c) \in \rho \land (b, c) \in \sigma && \text{Def. $\cap$} \\
                \dot\implies & (a, b) \in \rho \land (b, c) \in \rho \land (a, b) \in \sigma \land (b, c) \in \sigma && \text{Commutativity of $\land$} \\
                \dot\implies & (a, c) \in \rho \land (a, c) \in \sigma && \rho, \sigma \text{ are transitive} \\
                \dot\implies & (a, c) \in (\rho \cap \sigma) && \text{Def. $\cap$} \\
            \end{aligned}
        $$

        Since $\rho \cap \sigma$ is reflexive, symmetric, and transitive, it is an equivalence relation on $A$.
    </div>
</Problem>

<Problem title="Equivalence Relation on Vector Spaces" source="Tobias Steinbrecher" difficulty="🐺">
  <div label="question">
    Let $V$ be a real vector space, and define a relation $\sim$ on $V$ as follows: For $u, v \in V$, we say $u \sim v$ if and only if $u - v \in W$, where $W$ is a subspace of $V$. Prove that this relation is an equivalence relation.
  </div>
   <div label="hint">
    To prove that $\sim$ is an equivalence relation, you need to verify that it satisfies the three properties of equivalence relations: reflexivity, symmetry, and transitivity. For reflexivity, consider $u - u$. For symmetry, think about how $u - v$ relates to $v - u$. For transitivity, check how the condition $u - v \in W$ and $v - w \in W$ combine.
  </div>
  <div label="answer">
    We need to prove that the relation $u \sim v$ (i.e., $u - v \in W$) is an equivalence relation. This requires verifying three properties: reflexivity, symmetry, and transitivity.

    **1. Reflexivity**:  
    For any $u \in V$, we have:
    $$
    u - u = 0
    $$
    Since $W$ is a subspace, $0 \in W$. Therefore, $u \sim u$, and the relation is reflexive.

    **2. Symmetry**:  
    Suppose $u \sim v$, which means $u - v \in W$. We need to show that $v \sim u$. Since $u - v \in W$ and $W$ is a subspace, we know that $-(u - v) = v - u \in W$ (because subspaces are closed under scalar multiplication by $-1$). Therefore, $v \sim u$, and the relation is symmetric.

    **3. Transitivity**:  
    Suppose $u \sim v$ and $v \sim w$, meaning $u - v \in W$ and $v - w \in W$. We need to show that $u \sim w$. Since $W$ is a subspace and is closed under addition, we have:
    $$
    (u - v) + (v - w) = u - w \in W
    $$
    Therefore, $u \sim w$, and the relation is transitive.

    Since the relation is reflexive, symmetric, and transitive, $\sim$ is an equivalence relation.
  </div>
</Problem>

### Combinatorics

<Callout emoji="☕️" type="info">
Once upon a time, in the mystical land of Lernphase, there came a fateful day when I innocently decided to tackle some "quick exercises" on relations. Easy, right? I'd seen problems like, "How many reflexive relations are there on a set of $n$ elements?" before. Armed with some intuition from graph theory and a sprinkle of combinatorics, I managed to crack it. "Not bad," I thought. "This was actually a fun exercise!" (Feel free to try it below.)

But then I started wondering... What if they ask about symmetric relations? What about transitive ones? What if they combine different properties? Damn! And what about partial order relations or equivalence? That's when things started to spiral. In the spirit of thoroughness, I began constructing this giant table, trying to work out every possible combination myself. I figured I could add the formulas to my cheat sheet later. Little did I know what I was getting into.

I really should have read the Wikipedia article beforehand—because when I got to transitive relations, I was stuck for hours. There was no simple solution in sight. At some point, I thought, "Surely, they won't ask this on the exam.". But something wouldn't let me quit. So, I first shifted to counting partial order relations, thinking they might be easier since they have more structure. Still, I couldn't let go of the problem.

In a last-ditch effort, I started writing brute-force programs to count relations and derived some recurrences that seemed to work. Of course, verifying this recurrence and brute-forcing larger sets wasn't feasible because there were just too many possibilities.

I won't tell you how it ended. You'll have to figure that out yourself! But you'll definitely learn a lot about combinatorics and graphs in the process.

Check out the problems below. The first few are good practice, but if you're feeling adventurous, try the hard ones! Otherwise, skimming the [Wikipedia](https://en.wikipedia.org/wiki/Transitive_relation#Counting_transitive_relations) article first might save you some headaches.
</Callout>

<Problem title="Number of relations" source="Max Obreiter">
    <div label="question">
        How many relations are there from a finite set $A$ to a finite set $B$?
    </div>
    <div label="answer">
        Let's call the set of all relations from $A$ to $B$ $\texttt{rel}(A, B)$. Then by definition of a relation we have for any $\rho$:
        $$
            \rho \in \texttt{rel}(A, B) \iff \rho \subseteq A \times B
        $$
        This definition looks familiar; $\texttt{rel}(A, B)$ is the power set of $A \times B$!. So the number of relations from $A$ to $B$ is:
        $$
            |\texttt{rel}(A, B)| = 2^{|A \times B|} = 2^{|A| \cdot |B|}
        $$
    </div>
</Problem>

<Problem title="Number of reflexive relations" source="Tobias Steinbrecher">
      <div label="question" >
      How many reflexive relations are there on a set of $n$ elements?
      </div>
      <div label="hint">What are the *restrictions* of a reflexive relation? How many possibilities do we have to *choose* the rest freely?</div>
      <div label="answer">
       There are
       $$
       2^{n (n-1)}
       $$
       reflexive relations on a set of $n$ elements. We can decide for each tupel $(a,b) \in (A,B)$ whether it should be part of our relation or not. Except when $a = b$, then we need it in our relation to ensure reflexivity. How many pair remain? Exactly $n (n-1)$ (we can choose $n$ elements for the first element of the pair and then for each of those, $n-1$ for the second). Because for each pair, we can decide whether we want to take it or not (two choices), we obtain $2^{n (n-1)}$.
      </div>
</Problem>

<Problem title="Number of symmetric relations">
      <div label="question" >
      How many symmetric relations are there on a set of $n$ elements?
      </div>
      <div label="answer">
       There are
       $$
       2^{n(n+1)/2}
       $$
       symmetric relations on a set of $n$ elements. What can we decide for each tupel $(a,b) \in (A,B)$?  Consider $a = b$, then symmetry does not impose any constraints, thus, we can freely decide whether we want to take it or not (this gives us a factor of $2^n$). Now, if $a \neq b$, if we take the pair $(a,b)$, then we must also take $(b,a)$ (by symmetry). However, we could also decide to choose neither $(a,b)$ nor $(b,a)$. In the graph representation, we can decide for each pair of nodes, whether we want to put an *undirected* edge (formally directed edges in both directions). There are ${n \choose 2} = n(n-1)/2$ such pairs. Thus, we obtain a total of
       $$
       2^(n(n-1)/2) 2^{n} = 2^{(n^2 - n + 2 n)/2} = 2^{n (n+1) /2}
       $$
      </div>
</Problem>

<Problem title="Number of Irreflexive Relations">
  <div label="question">
    How many irreflexive relations are there on a set of $n$ elements?
  </div>
  <div label="hint">
    What does it mean for a relation to be irreflexive? How many pairs $(a, a)$ must be excluded from the relation?
  </div>
  <div label="answer">
    A relation is irreflexive if no element is related to itself. For each element $a$, the pair $(a, a)$ cannot be in the relation. There are $n$ such pairs to exclude, which leaves us with $n^2 - n$ pairs where we are free to choose whether or not to include them in the relation. Therefore, the total number of irreflexive relations is:
    $$
    2^{n(n-1)}
    $$
    since we can make a choice for each of the remaining $n(n-1)$ pairs.
  </div>
</Problem>

<Problem title="Number of antisymmetric relations">
<div label="question">
How many anti-symmetric relations are there on a set of $n$ elements?
</div>
<div label="hint">
What does anti-symmetry imply about pairs $(a,b)$ and $(b,a)$? How many choices are there for each pair when $a \neq b$?
</div>
<div label="answer">
For anti-symmetric relations, if $(a,b)$ is in the relation, $(b,a)$ cannot be, unless $a = b$.
- For each pair $(a,b)$ where $a \neq b$, there are three possibilities:
  1. Include $(a,b)$ but not $(b,a)$.
  2. Include $(b,a)$ but not $(a,b)$.
  3. Exclude both $(a,b)$ and $(b,a)$.


Thus, for each pair $(a,b)$ where $a \neq b$, we have 3 choices. There are $\frac{n(n-1)}{2}$ such pairs.

- For the pairs where $a = b$, there are $n$ such pairs, and for each one, we can either include or exclude it, giving us 2 choices per diagonal element.

So, the total number of anti-symmetric relations is:
$$
3^{\frac{n(n-1)}{2}} \cdot 2^n
$$
</div>
</Problem>

<Problem title="Number of Reflexive and Symmetric Relations">
  <div label="question">
    How many relations are both reflexive and symmetric on a set of $n$ elements?
  </div>
  <div label="hint">
    Reflexivity implies that all pairs $(a, a)$ must be included. Symmetry imposes a restriction on pairs $(a, b)$ and $(b, a)$.
  </div>
  <div label="answer">
  Think about the matrix representation here!
    Since the relation must be reflexive, all $n$ diagonal elements $(a, a)$ must be included. Symmetry implies symmetry of the matrix, we could count the number of elements in the upper half of the matrix, excluding the diagonal or use the following argument. For pairs $(a, b)$ with $a \neq b$, symmetry requires that either both $(a, b)$ and $(b, a)$ are included, or neither is included. There are ${n \choose 2} = n(n-1)/2$ such pairs, and for each pair, we have 2 choices: include both or include neither. Therefore, the total number of reflexive and symmetric relations is:
    $$
    2^{n(n-1)/2}
    $$
  </div>
</Problem>

<Problem title="Number of Equivalence Relations" difficulty="🦕" source="Tobias Steinbrecher">
  <div label="question">
    How many equivalence relations are there on a set of $n$ elements?
  </div>
  <div label="hint">
    Recall that an equivalence relation is reflexive, symmetric, and transitive. The number of equivalence relations corresponds to the number of partitions of the set.
    Think about how adding a new element to the set affects the number of possible partitions (equivalence relations).
  </div>
  <div label="answer">
    The number of equivalence relations on a set of $n$ elements is given by the $n$-th Bell number, $B_n$. The Bell numbers count the number of ways to partition a set into non-empty subsets. For small values of $n$, the Bell numbers are:
    $$
    B_1 = 1, \quad B_2 = 2, \quad B_3 = 5, \quad B_4 = 15, \quad B_5 = 52
    $$

    The recurrence for Bell numbers is:
    $$
    B_{n+1} = \sum_{k=0}^{n} {n \choose k} B_k
    $$

    **Intuition Behind the Recurrence**:
    The recurrence works by considering how we can form a partition of $n+1$ elements from a partition of $n$ elements. Here's the intuition:

    - The *new* item we added must be in some set of the partition. Except for this item itself, let's say there are $k$ other items which are **not** in this same set of the partition ($k$ can range here from $0$ to $n$, because we could also put the $n+1$-the item in a singleton partition).

    - Now we remove the whole partition of the $n+1$-th item. To partition the remaining set, we are left with $B_k$ possibilities. Additionally, there are $n \choose k$ possibilities to choose these $k$ items, which are not in the same partition as the $n+1$-th item.
  </div>
</Problem>

<Problem title="Number of transitive relations" difficulty="🐉">
<div label="question">
How many transitive relations are there on a set of $n$ elements?
</div>
<div label="hint">
interesting problem
</div>
<div label="answer">
**Unsolved problem** 🙃
The number of transitive relations is a more complex counting problem. For $n$-element sets, the known values of the number of transitive relations are:
$$
n = 1: \ 1, \quad n = 2: \ 2, \quad n = 3: \ 12, \quad n = 4: \ 3994 \quad  ...
$$
see [OEIS: Number of transitive relations](https://oeis.org/A006905).
</div>
</Problem>

## References

To delve deeper into this topic the [Wikipedia Article](https://en.wikipedia.org/wiki/Relation_(mathematics)) is actually quite interesting and not bloated with stuff which involves higher level mathematics.
